{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.chatbot import chat_model\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Medicaid managed care is a system where state Medicaid programs contract with managed care organizations (MCOs) to provide healthcare services to Medicaid enrollees. In this model, the MCOs assume the risk and responsibility for providing a defined set of healthcare services to enrolled Medicaid beneficiaries, often in exchange for a fixed monthly payment per member.\\n\\nUnder Medicaid managed care, enrollees typically choose a primary care provider (PCP) from a network of participating healthcare providers who coordinate their care. The MCOs manage the delivery of healthcare services, including authorizing and paying for medically necessary services, coordinating specialty care, and emphasizing preventive care.\\n\\nMedicaid managed care plans can vary in their specific designs and may include models such as:\\n\\n1. Health Maintenance Organizations (HMOs): Enrollees typically need to seek care from providers within the HMO's network, except in emergencies.\\n\\n2. Preferred Provider Organizations (PPOs): Enrollees can use providers outside the network but typically pay more for those services.\\n\\n3. Primary Care Case Management (PCCM) Models: These plans emphasize the role of the primary care provider in coordinating and managing the enrollee's care.\\n\\nThe goal of Medicaid managed care is to improve access to healthcare services, enhance care coordination, and potentially reduce costs for Medicaid programs by emphasizing preventive care and managing the utilization of healthcare services.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "     SystemMessage(\n",
    "         content=\"\"\"You're an assistant knowledgeable about\n",
    "         healthcare. Only answer healthcare-related questions.\"\"\"\n",
    "     ),\n",
    "     HumanMessage(content=\"What is Medicaid managed care?\"),\n",
    "]\n",
    "chat_model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"Your job is to use patient\\nreviews to answer questions about their experience at a\\nhospital. Use the following context to answer questions.\\nBe as detailed as possible, but don't make up any information\\nthat's not from the context. If you don't know an answer, say\\nyou don't know.\\n\\nI had a great stay!\\n\"),\n",
       " HumanMessage(content='Did anyone have a positive experience?')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "\n",
    "review_system_template_str = \"\"\"Your job is to use patient\n",
    "reviews to answer questions about their experience at a\n",
    "hospital. Use the following context to answer questions.\n",
    "Be as detailed as possible, but don't make up any information\n",
    "that's not from the context. If you don't know an answer, say\n",
    "you don't know.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "review_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=review_system_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "review_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"], template=\"{question}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "messages = [review_system_prompt, review_human_prompt]\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    messages=messages,\n",
    ")\n",
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive experience?\"\n",
    "\n",
    "review_prompt_template.format_messages(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]\n",
    "REVIEWS_CSV_PATH = \"data/reviews.csv\"\n",
    "REVIEWS_CHROMA_PATH = \"llm/chroma_data\"\n",
    "\n",
    "\n",
    "# loader = CSVLoader(file_path=REVIEWS_CSV_PATH, source_column=\"review\")\n",
    "# reviews = loader.load()\n",
    "\n",
    "# reviews_vector_db = Chroma.from_documents(\n",
    "#     reviews, CohereEmbeddings(), persist_directory=REVIEWS_CHROMA_PATH\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut DataFrame 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9998 entries, 0 to 9997\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   patient_id             9998 non-null   int64  \n",
      " 1   date_of_admission      9998 non-null   object \n",
      " 2   billing_amount         9998 non-null   float64\n",
      " 3   room_number            9998 non-null   int64  \n",
      " 4   admission_type         9998 non-null   object \n",
      " 5   discharge_date         9498 non-null   object \n",
      " 6   test_results           9998 non-null   object \n",
      " 7   visit_id               9998 non-null   int64  \n",
      " 8   physician_id           9998 non-null   int64  \n",
      " 9   payer_id               9998 non-null   int64  \n",
      " 10  hospital_id            9998 non-null   int64  \n",
      " 11  chief_complaint        3000 non-null   object \n",
      " 12  treatment_description  3000 non-null   object \n",
      " 13  primary_diagnosis      3000 non-null   object \n",
      " 14  visit_status           9998 non-null   object \n",
      "dtypes: float64(1), int64(6), object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "visits = pd.read_csv(\"data/visits.csv\")\n",
    "visits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = visits[:20]\n",
    "visits.to_csv(\"data/visits_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pd.read_csv('data/patients.csv')\n",
    "patient = patient[:20]\n",
    "patient.to_csv(\"data/patients_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician = pd.read_csv(\"data/physicians.csv\")\n",
    "physician = physician[:20]\n",
    "physician.to_csv(\"data/physician_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data visit to build relationship every data using id, something like visit_id, physician_id, payer_id, hospital_id and patient_id and review_id from data reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    CSVLoader(\"data/summary/hospital_summary.csv\", source_column=\"summary\"),\n",
    "    CSVLoader(\"data/summary/patient_summary.csv\", source_column=\"summary\"),\n",
    "    CSVLoader(\"data/summary/payer_summary.csv\", source_column=\"summary\"),\n",
    "    CSVLoader(\"data/summary/physician_summary.csv\", source_column=\"summary\"),\n",
    "    CSVLoader(\"data/summary/visit_summary.csv\", source_column=\"summary\"),\n",
    "    CSVLoader(\"data/reviews.csv\", source_column=\"review\"),\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=CohereEmbeddings(cohere_api_key=COHERE_API_KEY)\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "import uuid\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore alone retrieves the small chunks\n",
    "retriever.vectorstore.similarity_search(\"justice breyer\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Review Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 19:39:36 [INFO] Setting up vector chain...\n",
      "2024-05-29 19:39:36 [INFO] Load CohereEmbedding...\n",
      "2024-05-29 19:39:37 [INFO] Attempting to set up Neo4j vector index from existing index...\n",
      "2024-05-29 19:39:43 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response time: 3.231100559234619 seconds\n",
      "Response : The patient expresses gratitude for the compassionate and thorough medical care received at the hospital. The medical team is praised for their attentive and supportive nature, ensuring a comfortable and smooth recovery. The facilities are described as top-notch, modern, and well-equipped, contributing to a positive overall experience. This review highlights the excellent standard of care and the patient's satisfaction with their stay.\n"
     ]
    }
   ],
   "source": [
    "from llm_api.src.chains.review_chain import setup_vector_chain\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "query = \"\"\"give me the best patient review.\"\"\"\n",
    "vector_chain = setup_vector_chain()\n",
    "start_time = time.time()\n",
    "response = vector_chain.invoke(query)\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "res = response.get(\"result\")\n",
    "print(f\"\\nResponse time: {response_time} seconds\")\n",
    "print(\"Response :\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cypher Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:09:55 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (v:Visit)\n",
      "WHERE v.admission_type = 'Emergency'\n",
      "RETURN v.admission_type, v.status, COUNT(*) AS emergency_count;\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'v.admission_type': 'Emergency', 'v.status': 'OPEN', 'emergency_count': 174}, {'v.admission_type': 'Emergency', 'v.status': 'DISCHARGED', 'emergency_count': 3193}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:09:58 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Response time: 11.51573657989502 seconds\n",
      "Response : There are a total of 3367 admission-type emergencies. Of these, 174 are currently open, while 3193 have been discharged.\n"
     ]
    }
   ],
   "source": [
    "from llm_api.src.chains.cyper_chain import create_cypher_qa_chain\n",
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# question = \"\"\"I need information about the visit on 2022-03-08 such as chief complaint, treatment and payment status.\"\"\"\n",
    "# question =\"\"\"\n",
    "#     I was looking for a patient but forgot his name, \n",
    "#     I only know his date of birth is 1989-01-26 and his blood type is AB+. \n",
    "#     And is he still being treated and in which room?\n",
    "# \"\"\"\n",
    "# question = \"\"\"Which state had the largest percent increase\n",
    "#            in Medicaid visits from 2022 to 2023?\"\"\"\n",
    "question = \"\"\"\n",
    "    I want to know how many admission type emegencies there are and what their status is.\n",
    "\"\"\"\n",
    "# question = \"how many patients did Jason Williams treat while working at the hospital\"\n",
    "\n",
    "cypher_qa_chain = create_cypher_qa_chain()\n",
    "start_time = time.time()\n",
    "response = cypher_qa_chain.invoke(question)\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "res = response.get(\"result\")\n",
    "print(f\"\\nResponse time: {response_time} seconds\")\n",
    "print(\"Response :\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Rag agent\n",
    "**Note:** sometimes we need to rerun the code to get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 21:22:22 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "I will search for the physician who has treated the most patients covered by Cigna.\n",
      "{'tool_name': 'Graph', 'parameters': {'tool_input': 'Which physician has treated the most patients covered by Cigna?'}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 21:22:28 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Payer)<--(:Visit)<-[t:TREATS]-(phy:Physician)\n",
      "WHERE p.name = 'Cigna'\n",
      "RETURN phy.name AS physician_name, COUNT(DISTINCT t) AS num_patients_treated\n",
      "ORDER BY num_patients_treated DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'physician_name': 'Amy Daniels', 'num_patients_treated': 13}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 21:22:36 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{'query': 'Which physician has treated the most patients covered by Cigna?', 'result': 'Amy Daniels has treated 13 patients covered by Cigna, making her the physician with the most Cigna patients treated.'}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 21:22:37 [INFO] HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mRelevant Documents: 0\n",
      "Cited Documents: 0\n",
      "Answer: Amy Daniels has treated 13 patients covered by Cigna, making her the physician with the most Cigna patients treated.\n",
      "Grounded answer: <co: 0>Amy Daniels</co: 0> has treated <co: 0>13 patients covered by Cigna</co: 0>, making her the physician with the most Cigna patients treated.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Response time: 19.148507356643677 seconds\n",
      "Response : Amy Daniels has treated 13 patients covered by Cigna, making her the physician with the most Cigna patients treated.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from llm_api.src.agents.rag_agent import agent_executor\n",
    "\n",
    "# question = {\"input\": \"What is the wait time at Wallace-Hamilton?\"}\n",
    "# question = {\n",
    "#          \"input\": (\n",
    "#              \"What have patients said about their \"\n",
    "#              \"quality of rest during their stay?\"\n",
    "#          )\n",
    "#      }\n",
    "\n",
    "question = {\n",
    "    \"input\": (\n",
    "        \"Which physician has treated the \"\n",
    "        \"most patients covered by Cigna?\"\n",
    "    )\n",
    "}\n",
    "\n",
    "agent = agent_executor()\n",
    "start_time = time.time()\n",
    "response = agent.invoke(question)\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "res = response.get(\"output\")\n",
    "print(f\"\\nResponse time: {response_time} seconds\")\n",
    "print(\"Response :\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
