# LangChain + FastAPI

## Usage
```bash
cd api
uvicorn main:app --reload
```


## Refrence
- [Streaming Locally Deployed LLM Responses Using FastAPI](https://blog.stackademic.com/streaming-llm-responses-using-fastapi-deb575554397)
- [Streaming Responses from LLM Using LangChain + FastAPI](https://blog.stackademic.com/streaming-responses-from-llm-using-langchain-fastapi-329f588d3b40)
- [Stream OpenAI respond through FastAPI to Next.js](https://medium.com/@timnirmal/stream-openai-respond-through-fastapi-to-next-js-f5395f69687c)
- [How to use Streaming in LangChain and Streamlit](https://alejandro-ao.com/how-to-use-streaming-in-langchain-and-streamlit/)